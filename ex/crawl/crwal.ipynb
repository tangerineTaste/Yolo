{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4251f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting icrawler\n",
      "  Downloading icrawler-0.6.10-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting beautifulsoup4 (from icrawler)\n",
      "  Downloading beautifulsoup4-4.13.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bs4 (from icrawler)\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting lxml (from icrawler)\n",
      "  Downloading lxml-6.0.1-cp313-cp313-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting pillow (from icrawler)\n",
      "  Using cached pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pyyaml (from icrawler)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests (from icrawler)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: six in c:\\users\\601\\appdata\\roaming\\python\\python313\\site-packages (from icrawler) (1.17.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->icrawler)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4->icrawler)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->icrawler)\n",
      "  Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->icrawler)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->icrawler)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->icrawler)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading icrawler-0.6.10-py3-none-any.whl (36 kB)\n",
      "Downloading beautifulsoup4-4.13.5-py3-none-any.whl (105 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading lxml-6.0.1-cp313-cp313-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/4.0 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 8.3 MB/s  0:00:00\n",
      "Using cached pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, soupsieve, pyyaml, pillow, lxml, idna, charset_normalizer, certifi, requests, beautifulsoup4, bs4, icrawler\n",
      "\n",
      "   ----------------------------------------  0/13 [urllib3]\n",
      "   ----------------------------------------  0/13 [urllib3]\n",
      "   ----------------------------------------  0/13 [urllib3]\n",
      "   --- ------------------------------------  1/13 [typing-extensions]\n",
      "   ------ ---------------------------------  2/13 [soupsieve]\n",
      "   --------- ------------------------------  3/13 [pyyaml]\n",
      "   ------------ ---------------------------  4/13 [pillow]\n",
      "   ------------ ---------------------------  4/13 [pillow]\n",
      "   ------------ ---------------------------  4/13 [pillow]\n",
      "   ------------ ---------------------------  4/13 [pillow]\n",
      "   ------------ ---------------------------  4/13 [pillow]\n",
      "   ------------ ---------------------------  4/13 [pillow]\n",
      "   ------------ ---------------------------  4/13 [pillow]\n",
      "   ------------ ---------------------------  4/13 [pillow]\n",
      "   ------------ ---------------------------  4/13 [pillow]\n",
      "   ------------ ---------------------------  4/13 [pillow]\n",
      "   --------------- ------------------------  5/13 [lxml]\n",
      "   --------------- ------------------------  5/13 [lxml]\n",
      "   --------------- ------------------------  5/13 [lxml]\n",
      "   ------------------ ---------------------  6/13 [idna]\n",
      "   --------------------- ------------------  7/13 [charset_normalizer]\n",
      "   --------------------- ------------------  7/13 [charset_normalizer]\n",
      "   --------------------------- ------------  9/13 [requests]\n",
      "   --------------------------- ------------  9/13 [requests]\n",
      "   ------------------------------ --------- 10/13 [beautifulsoup4]\n",
      "   ------------------------------ --------- 10/13 [beautifulsoup4]\n",
      "   ------------------------------------ --- 12/13 [icrawler]\n",
      "   ------------------------------------ --- 12/13 [icrawler]\n",
      "   ---------------------------------------- 13/13 [icrawler]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.13.5 bs4-0.0.2 certifi-2025.8.3 charset_normalizer-3.4.3 icrawler-0.6.10 idna-3.10 lxml-6.0.1 pillow-11.3.0 pyyaml-6.0.2 requests-2.32.5 soupsieve-2.8 typing-extensions-4.15.0 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install icrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680141b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './see_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae64b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icrawler.builtin import GoogleImageCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72f6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_crawler = GoogleImageCrawler(storage={'root_dir' : save_dir})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829cc1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 09:41:23,446 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-17 09:41:23,447 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-17 09:41:23,451 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-17 09:41:23,457 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-17 09:41:23,465 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
      "2025-09-17 09:41:24,840 - INFO - parser - parsing result page https://www.google.com/search?q=%EB%B0%94%EB%8B%A4&ijn=0&start=0&tbs=&tbm=isch\n",
      "2025-09-17 09:41:25,702 - INFO - downloader - image #1\thttps://cdn.travie.com/news/photo/202505/54296_39721_226.jpg\n",
      "2025-09-17 09:41:26,306 - INFO - downloader - image #2\thttps://gscaltexmediahub.com/wp-content/uploads/2023/05/the-day-of-ocean-2023_1.png\n",
      "2025-09-17 09:41:26,334 - INFO - downloader - image #3\thttps://cdn.travie.com/news/photo/202505/54296_39738_207.jpg\n",
      "2025-09-17 09:41:27,257 - INFO - downloader - image #4\thttps://images.unsplash.com/photo-1507525428034-b723cf961d3e?fm=jpg\n",
      "2025-09-17 09:41:27,815 - INFO - downloader - image #5\thttps://m.health.chosun.com/site/data/img_dir/2023/05/31/2023053102582_0.jpg\n",
      "2025-09-17 09:41:30,091 - ERROR - downloader - Exception caught when downloading file https://png, error: HTTPSConnectionPool(host='png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000187D96D3250>: Failed to resolve 'png' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 2\n",
      "2025-09-17 09:41:32,372 - ERROR - downloader - Exception caught when downloading file https://png, error: HTTPSConnectionPool(host='png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000187D96D3750>: Failed to resolve 'png' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 1\n",
      "2025-09-17 09:41:34,645 - ERROR - downloader - Exception caught when downloading file https://png, error: HTTPSConnectionPool(host='png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000187D96D3B10>: Failed to resolve 'png' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 0\n",
      "2025-09-17 09:41:34,655 - ERROR - downloader - Exception caught when downloading file https://kor.png, error: HTTPSConnectionPool(host='kor.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000187D96D3ED0>: Failed to resolve 'kor.png' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 2\n",
      "2025-09-17 09:41:34,659 - ERROR - downloader - Exception caught when downloading file https://kor.png, error: HTTPSConnectionPool(host='kor.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000187D9B08410>: Failed to resolve 'kor.png' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 1\n",
      "2025-09-17 09:41:34,663 - ERROR - downloader - Exception caught when downloading file https://kor.png, error: HTTPSConnectionPool(host='kor.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000187D96D3ED0>: Failed to resolve 'kor.png' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 0\n",
      "2025-09-17 09:41:35,581 - INFO - downloader - downloaded images reach max num, thread downloader-001 is ready to exit\n",
      "2025-09-17 09:41:35,582 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-17 09:41:36,488 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 09:41:36,670 - INFO - parser - downloaded image reached max num, thread parser-001 is ready to exit\n",
      "2025-09-17 09:41:36,670 - INFO - parser - thread parser-001 exit\n"
     ]
    }
   ],
   "source": [
    "google_crawler.crawl(keyword='바다', max_num=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
